{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入套件 要引入到(base才可以在這用)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>Hello</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <p>Hello World!</p>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://www.ehappy.tw/demo.htm'\n",
    "r = requests.get(url)\n",
    "if r.status_code == requests.codes.ok:\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Http request\n",
    "### get and post with parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.24.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-5f337ae2-29ef8bcf003f86b797fa32ba\"\n",
      "  }, \n",
      "  \"origin\": \"59.127.49.239\", \n",
      "  \"url\": \"http://httpbin.org/get?key1=value1&key2=value2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "payload = {'key1':'value1','key2':'value2'}\n",
    "r = requests.get(\"http://httpbin.org/get\", params=payload)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.24.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-5f337c25-db71f68998db9547de20fe6c\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"59.127.49.239\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "payload = {'key1':'value1','key2':'value2'}\n",
    "r = requests.post(\"http://httpbin.org/post\", data=payload)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse\n",
    "### use BeautifulSoup to get goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>我是網頁標題</title>\n",
      "我是網頁標題\n",
      "<h1 class=\"large\">我是標題</h1>\n",
      "<p>我是段落</p>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://ehappy.tw/bsdemo1.htm'\n",
    "html = requests.get(url)\n",
    "html.encoding = 'UTF-8'\n",
    "sp = BeautifulSoup(html.text,'lxml')\n",
    "print(sp.title)\n",
    "print(sp.title.text)\n",
    "print(sp.h1)\n",
    "print(sp.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"p1\">我是第一段</p>\n",
      "[<p id=\"p1\">我是第一段</p>, <p class=\"red\" id=\"p2\">我是第二段</p>]\n",
      "<p class=\"red\" id=\"p2\">我是第二段</p>\n",
      "<p class=\"red\" id=\"p2\">我是第二段</p>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <meta charset = \"UTF-8\">\n",
    "            <title>我是標題網頁</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div>\n",
    "                <p id='p1'>我是第一段</p>\n",
    "                <p id='p2' class='red'>我是第二段</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "'''\n",
    "\n",
    "sp = BeautifulSoup(html,'lxml')\n",
    "print(sp.find('p')) #找第一個\n",
    "print(sp.find_all('p')) #找全部\n",
    "print(sp.find('p',{'id':'p2','class':'red'}))\n",
    "print(sp.find('p',id='p2',class_ = 'red')) #效果與上一行相同, class為關鍵字 所以補上底線才可認定為變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>我是標題網頁</title>]\n",
      "[<p id=\"p1\">我是第一段</p>, <p class=\"red\" id=\"p2\">我是第二段</p>]\n",
      "[<p id=\"p1\">我是第一段</p>]\n",
      "[<p class=\"red\" id=\"p2\">我是第二段</p>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <meta charset = \"UTF-8\">\n",
    "            <title>我是標題網頁</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div>\n",
    "                <p id='p1'>我是第一段</p>\n",
    "                <p id='p2' class='red'>我是第二段</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "'''\n",
    "\n",
    "sp = BeautifulSoup(html,'lxml')\n",
    "print(sp.select('title')) \n",
    "print(sp.select('p')) \n",
    "print(sp.select('#p1'))\n",
    "print(sp.select('.red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ehappy.tw/python.png\n",
      "http://www.e-happy.com.tw\n",
      "http://www.ehappy.tw/python.png\n",
      "http://www.e-happy.com.tw\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<title>我是網頁標題</title>\n",
    "</head>\n",
    "<body>\n",
    "<img src=\"http://www.ehappy.tw/python.png\">\n",
    "<a href=\"http://www.e-happy.com.tw\">超連結</a>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "sp = BeautifulSoup(html,'lxml')\n",
    "print(sp.select('img')[0].get('src')) \n",
    "print(sp.select('a')[0].get('href')) \n",
    "print(sp.select('img')[0]['src']) \n",
    "print(sp.select('a')[0]['href']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實際爬蟲範例\n",
    "### 爬威力彩號碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "威力彩林俊佑期數:109/8/10 第109000064期 \n",
      "開出順序: 06  15  22  04  19  05 \n",
      "大小順序: 04  05  06  15  19  22 \n",
      "第二區:03 \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://www.taiwanlottery.com.tw'\n",
    "html = requests.get(url)\n",
    "html.encoding = 'UTF-8'\n",
    "sp = BeautifulSoup(html.text,'lxml')\n",
    "print( '威力彩林俊佑期數:' +sp.select('.contents_mine_tx02')[0].select('span')[0].text)\n",
    "s = ''\n",
    "for i in range(3,9):\n",
    "    s += ' ' + sp.select('.contents_box02')[0].select('div')[i].text\n",
    "print( '開出順序:' + s)\n",
    "s = ''\n",
    "for i in range(9,15):\n",
    "    s += ' ' + sp.select('.contents_box02')[0].select('div')[i].text\n",
    "print( '大小順序:' + s)\n",
    "print('第二區:' + sp.select('.contents_box02')[0].select('div')[15].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python 抓 youtube影片的 套件 範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\a0970\\\\Desktop\\\\python_exercise\\\\climb\\\\麋先生MIXER【某某某 Someone】Official Music Video.mp4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "yt = YouTube('https://www.youtube.com/watch?v=pkSjkse6j-o')\n",
    "yt.streams.first().download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
